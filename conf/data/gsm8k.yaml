dataset: gsm8k
batch_size: 1
chain_split: train
eval_split: test

# Transform
transform:
  _target_: utils.data_processor.prepare_integer_math_example
  _partial_: true

# Regex
answer_regex: Answer:\s*(\d+)

# Model
params_data:
  # Each param is defined as a DictConfig here and then will be parsed into a dataclass
  - name: system_prompt
    value: Answer the math question. Think step-by-step.
    role: system prompt for a math question-answering language model
    addendum: >-
      The last line of your response must always and only be of the following
      format: "Answer: VALUE" (without quotes) where VALUE is a numerical value.
    addendum_role: formatting instructions for the last line of the language model's response

# Proposal
likelihood_loss_text: >-
  You will be given a math question and an answer attempted by a language
  model. Evaluate the attempted answer. Be smart, logical, and very critical.
  Do not solve the question. Just provide concise feedback.
likelihood_loss_role: answer evaluation instructions for the math task
likelihood_loss_input_roles: ["question", "correct answer", "attempted answer"]

# MCMC
likelihood_answer_regex: (Answer:\s*)\d+
likelihood_param_addendum: >-
  The last line of your response must always and only be of the following
  format: "Answer: VALUE" (without quotes) where VALUE is a numerical value.
prior_meta_prompts:
  # Each param can have its own prior -- make sure the order is the same as in `params_data` above
  - >-
    Generate a good system prompt for a math question-answering language
    model. The system prompt must be concise and generic and works with any question.

# Evaluation
evaluator:
  _target_: evaluation.datasets.IntegerMathEvaluator
  _partial_: true
  answer_regex: ${data.answer_regex}

baseline_eval_fn:
  _target_: method.baseline.evaluate.baseline_int
  _partial_: true
  answer_regex: ${data.answer_regex}
